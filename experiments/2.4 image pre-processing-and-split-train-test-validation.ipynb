{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe68e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from dataclasses import dataclass\n",
    "import pathlib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cc30ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DatasetConfig:\n",
    "    SEED_VALUE:  int = 41\n",
    "    CUT_PLANE:   str = \"escolha do corte: sagital/coronal\"\n",
    "         \n",
    "    DATA_ROOT_SOURCE_PATH: str = 'caminho do dataset'\n",
    "    MAIN_DATA_CSV_PATH: str = DATA_ROOT_SOURCE_PATH + '\\\\fdg_metadata.csv'\n",
    "    DATA_ROOT_TARGET:  str = f'caminho de onde será gerados as imagens{CUT_PLANE}' \n",
    "    DATA_ROOT_TRAIN:  str = DATA_ROOT_TARGET + '/Train' \n",
    "    DATA_ROOT_VALID:  str = DATA_ROOT_TARGET + '/Valid'\n",
    "    DATA_ROOT_TEST:   str = DATA_ROOT_TARGET + '/Test'\n",
    "    DATA_TEST_GT:     str = DATA_ROOT_TARGET + '/Test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19efa5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, val and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbdfb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(DatasetConfig.DATA_ROOT_TARGET + \"/data_description.csv\")\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d744dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd845314",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = data_df.columns.to_list()\n",
    "col_names[0] = \"imageId\"\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f5d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns = col_names\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f8d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new height will be based on the mean value\n",
    "#data_df.width.mean()\n",
    "\n",
    "#novo height ou width baseado no valor máximo\n",
    "data_df[\"width\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70be425",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ImageResizeConfig:\n",
    "    height: int = 400 # VALOR MÁXIMO DE HEIGHT\n",
    "    width: int = 661 # VALOR MÁXIMO DE WIDTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19add49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_and_export_record(row):\n",
    "    image_path = DatasetConfig.DATA_ROOT_TARGET + row[\"filePath\"]\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    original_height, original_width = img.shape[:2] #Atuais dimensões atuais da imagem\n",
    "    scale_w = ImageResizeConfig.width / original_width\n",
    "    scale_h = ImageResizeConfig.height / original_height\n",
    "    scale = min(scale_w, scale_h)\n",
    "    \n",
    "    new_width = int(original_width * scale) #novo tamanho\n",
    "    new_height = int(original_height * scale)\n",
    "    img_resized = cv2.resize(img, (new_width, new_height)) #redimensionar mantendo a proporção\n",
    "    \n",
    "    img_padded = np.zeros((ImageResizeConfig.height, ImageResizeConfig.width, 3), dtype=np.uint8) #bordas pretas\n",
    "    x_offset = (ImageResizeConfig.width - new_width) // 2 #centralizar imagem\n",
    "    y_offset = (ImageResizeConfig.height - new_height) // 2\n",
    "    \n",
    "    # Colocar a imagem redimensionada no fundo preto\n",
    "    img_padded[y_offset:y_offset + new_height, x_offset:x_offset + new_width] = img_resized\n",
    "\n",
    "    img_gray = cv2.cvtColor(img_padded, cv2.COLOR_BGR2GRAY)\n",
    "    img_normalized = cv2.normalize(img_gray, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    \n",
    "    img_class = \"0\" if row.diagnosis == \"NEGATIVE\" else \"1\"\n",
    "    \n",
    "    destination_path = f\"{DatasetConfig.DATA_ROOT_TARGET}/{row.subset}/{img_class}\"\n",
    "    pathlib.Path(destination_path).mkdir(parents=True, exist_ok=True)\n",
    "    destination_path = f\"{destination_path}/{row.imageId}.png\"\n",
    "    \n",
    "    cv2.imwrite(destination_path, img_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076584ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"subset\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c185d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11012c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_patients = data_df[\"Subject ID\"].unique()\n",
    "unique_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d9a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_patients = pd.Series(unique_patients).sample(frac=1, random_state=DatasetConfig.SEED_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a71c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frac = 0.8\n",
    "val_frac = 0.1\n",
    "test_frac = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e2ab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patients = shuffled_patients[:int(train_frac * len(shuffled_patients))]\n",
    "val_patients = shuffled_patients[int(train_frac * len(shuffled_patients)):int((train_frac + val_frac) * len(shuffled_patients))]\n",
    "test_patients = shuffled_patients[int((train_frac + val_frac) * len(shuffled_patients)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4718e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_df[data_df[\"Subject ID\"].isin(train_patients)]\n",
    "val_df = data_df[data_df[\"Subject ID\"].isin(val_patients)]\n",
    "test_df = data_df[data_df[\"Subject ID\"].isin(test_patients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b77df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1, random_state=DatasetConfig.SEED_VALUE)\n",
    "val_df = val_df.sample(frac=1, random_state=DatasetConfig.SEED_VALUE)\n",
    "test_df = test_df.sample(frac=1, random_state=DatasetConfig.SEED_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb04448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf39ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea154ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1319466",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd31f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e241deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb3c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.subset = \"Train\"\n",
    "val_df.subset = \"Valid\"\n",
    "test_df.subset = \"Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75e76a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VERIFICAR VAZAMENTO DE DADOS\n",
    "\n",
    "def check_data_leakage(train_df, val_df, test_df):\n",
    "    # Obter os IDs dos pacientes (Subject ID) de cada conjunto\n",
    "    train_patients = set(train_df[\"Subject ID\"].unique())\n",
    "    val_patients = set(val_df[\"Subject ID\"].unique())\n",
    "    test_patients = set(test_df[\"Subject ID\"].unique())\n",
    "    \n",
    "    # Verificar interseção entre os conjuntos de pacientes\n",
    "    overlap_train_val = train_patients.intersection(val_patients)\n",
    "    overlap_train_test = train_patients.intersection(test_patients)\n",
    "    overlap_val_test = val_patients.intersection(test_patients)\n",
    "    \n",
    "    # Listar as interseções encontradas\n",
    "    if overlap_train_val:\n",
    "        print(f\"Vazamento detectado entre treino e validação: {overlap_train_val}\")\n",
    "    if overlap_train_test:\n",
    "        print(f\"Vazamento detectado entre treino e teste: {overlap_train_test}\")\n",
    "    if overlap_val_test:\n",
    "        print(f\"Vazamento detectado entre validação e teste: {overlap_val_test}\")\n",
    "    \n",
    "    # Se nenhum overlap for encontrado\n",
    "    if not (overlap_train_val or overlap_train_test or overlap_val_test):\n",
    "        print(\"Nenhum vazamento de dados detectado entre os conjuntos de treino, validação e teste.\")\n",
    "\n",
    "# Chamar a função de verificação antes de executar o pré-processamento\n",
    "check_data_leakage(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ef5cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.concat([train_df, val_df, test_df]).sample(frac=1,random_state=DatasetConfig.SEED_VALUE)\n",
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac5ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tqdm(full_data.iterrows(), total=len(full_data)):\n",
    "    pre_process_and_export_record(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd973b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Carregar a imagem\n",
    "image = cv2.imread(\"D:\\\\dataset_maior\\\\sagital\\\\l\\\\Train\\\\1\\\\6.png\")\n",
    "\n",
    "# Obter as dimensões\n",
    "altura, largura, canais = image.shape\n",
    "\n",
    "print(f\"Largura: {largura} pixels\")\n",
    "print(f\"Altura: {altura} pixels\")\n",
    "print(f\"Número de canais: {canais}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dd9f10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
